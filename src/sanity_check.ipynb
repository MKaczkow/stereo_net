{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from model import StereoNet\n",
    "import utils as utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_left_rgb_image_file = \\\n",
    "r'D:\\engineering_thesis_data\\Kitti_2015\\data_scene_flow\\training\\image_2\\000000_10.png'\n",
    "path_to_right_rgb_image_file = \\\n",
    "r'D:\\engineering_thesis_data\\Kitti_2015\\data_scene_flow\\training\\image_3\\000000_10.png'\n",
    "path_to_left_disp_file = \\\n",
    "r'D:\\engineering_thesis_data\\Kitti_2015\\data_scene_flow\\training\\disp_noc_0\\000000_10.pfm' \n",
    "\n",
    "# path_to_left_rgb_image_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\frames\\webp\\eating_x2\\left\\0009.webp'\n",
    "# path_to_right_rgb_image_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\frames\\webp\\eating_x2\\right\\0009.webp'\n",
    "# path_to_left_disp_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\disparity\\eating_x2\\left\\0009.pfm'\n",
    "\n",
    "# path_to_left_rgb_image_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\frames\\35mm_focallength\\scene_backwards\\fast\\left\\0087.webp'\n",
    "# path_to_right_rgb_image_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\frames\\35mm_focallength\\scene_backwards\\fast\\right\\0087.webp'\n",
    "# path_to_left_disp_file = \\\n",
    "# r'D:\\engineering_thesis_data\\SceneFlow\\Driving\\disparity\\35mm_focallength\\scene_backwards\\fast\\left\\0087.pfm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the image pair as numpy uint8 arrays\n",
    "# sample = {'left': utils.webp_loader(path_to_left_rgb_image_file),\n",
    "#           'right': utils.webp_loader(path_to_right_rgb_image_file)\n",
    "#           }\n",
    "\n",
    "sample = {'left': utils.image_loader(path_to_left_rgb_image_file),\n",
    "          'right': utils.image_loader(path_to_right_rgb_image_file)\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp_gt = utils.pfm_loader(path_to_left_disp_file)\n",
    "disp_gt, scale = utils.pfm_loader(path_to_left_disp_file)\n",
    "print(type(disp_gt), disp_gt.max(), disp_gt.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(disp_gt[0])\n",
    "plt.imshow(disp_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the single image pair into a torch.Tensor then into a\n",
    "# batch of shape [batch, channel, height, width]\n",
    "transformers = [\n",
    "    utils.ToTensor(), \n",
    "    utils.PadSampleToBatch(),\n",
    "    utils.Rescale()\n",
    "    ]\n",
    "    \n",
    "for transformer in transformers:\n",
    "    sample = transformer(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample))\n",
    "print(sample.keys())\n",
    "\n",
    "print(type(sample['left']))\n",
    "print(sample['left'].shape)\n",
    "print(sample['left'].max())\n",
    "print(sample['left'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample['left'].squeeze().moveaxis(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = StereoNet.load_from_checkpoint(\n",
    "    r'D:\\__repos\\engineering_thesis\\experiments\\model_checkpoints\\lightning_logs\\epoch=20-step=744533.ckpt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StereoNet.load_from_checkpoint(\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\epoch=20-step=744533.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_3\\checkpoints\\epoch=99-step=16000.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_3\\checkpoints\\epoch=10-step=1760.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_3\\checkpoints\\epoch=5-step=960.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_20\\checkpoints\\epoch=29-step=4800.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_35\\checkpoints\\epoch=0-step=753198.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_35\\checkpoints\\epoch=1-step=761862.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_38\\checkpoints\\epoch=0-step=784358.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_38\\checkpoints\\epoch=1-step=824182.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_38\\checkpoints\\epoch=2-step=864006.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_43\\checkpoints\\epoch=4-step=199120.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_48\\checkpoints\\epoch=15-step=2560.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_48\\checkpoints\\epoch=12-step=2080.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_48\\checkpoints\\epoch=8-step=1440.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_48\\checkpoints\\epoch=4-step=800.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_48\\checkpoints\\epoch=1-step=320.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_53\\checkpoints\\epoch=3-step=745174.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_53\\checkpoints\\epoch=7-step=745814.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_53\\checkpoints\\epoch=12-step=746614.ckpt'\n",
    "    # r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_53\\checkpoints\\epoch=17-step=747414.ckpt'\n",
    "    r'D:\\__repos\\engineering_thesis\\experiments\\src\\stereonet\\lightning_logs\\version_53\\checkpoints\\epoch=20-step=747894.ckpt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to eval and run the forward method without tracking gradients\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batched_prediction = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.eval()\n",
    "with torch.no_grad():\n",
    "    base_prediction = base_model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the batch diemnsion and switch back to channels last notation\n",
    "single_prediction = batched_prediction[0].numpy()  # [batch, ...] -> [...]\n",
    "single_prediction = np.moveaxis(single_prediction, 0, 2)  # [channel, height, width] -> [height, width, channel]\n",
    "\n",
    "single_base_prediction = base_prediction[0].numpy()  # [batch, ...] -> [...]\n",
    "single_base_prediction = np.moveaxis(single_base_prediction, 0, 2)  # [channel, height, width] -> [height, width, channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(base_prediction))\n",
    "print(base_prediction.shape)\n",
    "print(base_prediction.max())\n",
    "print(base_prediction.min())\n",
    "\n",
    "print()\n",
    "\n",
    "print(type(batched_prediction))\n",
    "print(batched_prediction.shape)\n",
    "print(batched_prediction.max())\n",
    "print(batched_prediction.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(single_base_prediction))\n",
    "print(single_base_prediction.shape)\n",
    "print(single_base_prediction.max())\n",
    "print(single_base_prediction.min())\n",
    "\n",
    "print()\n",
    "\n",
    "print(type(single_prediction))\n",
    "print(single_prediction.shape)\n",
    "print(single_prediction.max())\n",
    "print(single_prediction.min())\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(type(disp_gt))\n",
    "print(disp_gt.shape)\n",
    "print(disp_gt.max())\n",
    "print(disp_gt.min())\n",
    "\n",
    "\n",
    "# print(type(disp_gt[0]))\n",
    "# print(disp_gt[0].shape)\n",
    "# print(disp_gt[0].max())\n",
    "# print(disp_gt[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(single_base_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(single_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample['left']))\n",
    "print(type(sample['right']))\n",
    "print(type(disp_gt), disp_gt.max(), disp_gt.min())\n",
    "print(type(single_prediction), single_prediction.max(), single_prediction.min())\n",
    "\n",
    "figure = utils.plot_and_save_figure(sample['left'], sample['right'], disp_gt, single_prediction)\n",
    "# figure = utils.plot_and_save_figure(sample['left'], sample['right'], disp_gt[0], single_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample['left']))\n",
    "print(type(sample['right']))\n",
    "print(type(disp_gt), disp_gt.max(), disp_gt.min())\n",
    "print(type(single_base_prediction), single_base_prediction.max(), single_base_prediction.min())\n",
    "\n",
    "# figure = utils.plot_figure(sample['left'], sample['right'], disp_gt[0], single_base_prediction)\n",
    "figure = utils.plot_figure(sample['left'], sample['right'], disp_gt, single_base_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3 (tags/v3.10.3:a342a49, Mar 16 2022, 13:07:40) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69693019580ba9c11f54de22c8f781d46b90d5da4004b9c782de0327811b5f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
